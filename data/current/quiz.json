{
  "id": "pmle-20260212-",
  "exam_code": "PMLE",
  "domain": "モデルの提供とスケーリング",
  "section": "モデルの提供",
  "topic": "バッチ推論とオンライン推論の選択",
  "difficulty": "medium",
  "question": "ある小売企業は、1,000万人の顧客に対して、週に一度のプロモーションメールを送るための離脱予測スコアを算出しようとしています。対象となるデータはBigQueryに保存されており、リアルタイムの応答は必要ありません。Google Cloudのベストプラクティスに基づき、最も効率的かつコスト効率の高い予測方法はどれですか？",
  "options": [
    "Vertex AI Batch Predictionを使用し、BigQueryをデータソースおよび出力先として指定する。",
    "Vertex AI Endpointにモデルをデプロイし、Cloud Dataflowからストリーミングで予測リクエストを送信する。",
    "Vertex AI Endpointにモデルをデプロイし、Python SDKを使用して各レコードに対して個別にオンライン予測を実行する。",
    "Vertex AI Model Registryからモデルをダウンロードし、Compute Engine上で独自の推論サーバーを構築して処理する。"
  ],
  "correct": 0,
  "explanation": "このシナリオでは、大規模なデータセット（1,000万人分）を週に一度、非同期で処理することが求められています。Vertex AI Batch Predictionは、即時性を必要としない大量のデータを一括処理するのに最適であり、BigQueryと直接統合して効率的に処理できるため、コスト効率と運用効率の両面でベストプラクティスです。オンライン予測（選択肢B、C）は低レイテンシのリアルタイム応答には適していますが、大規模なバッチ処理に使用するとスロットリングやコスト増大、エンドポイント管理のオーバーヘッドが発生します。独自のサーバー構築（選択肢D）は、マネージドサービスの利点を損ない、運用負荷が高くなります。"
}
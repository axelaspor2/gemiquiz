{
  "id": "pmle-20260202-dataflow",
  "exam_code": "PMLE",
  "domain": "チーム内およびチーム間の連携によるデータとモデルの管理",
  "section": "組織全体のデータの探索と前処理",
  "topic": "Dataflow を使用したデータ前処理",
  "difficulty": "easy",
  "question": "あなたは、Dataflowを使用して大規模なデータセットの前処理を行い、機械学習モデルをトレーニングするパイプラインを構築しています。トレーニング時と推論（サービング）時で前処理ロジックが異なってしまう「トレーニング/サービング スキュー（training-serving skew）」を防ぐための、Google Cloud が推奨するベストプラクティスはどれですか？",
  "options": [
    "TensorFlow Transform (tf.Transform) を使用して前処理ロジックをグラフとしてエクスポートし、モデルの一部として組み込む。",
    "トレーニングデータに対してのみ前処理を行い、サービング時には生のデータをモデルに入力する。",
    "トレーニング用とサービング用に、それぞれ別の Dataflow パイプラインを独立して作成・保守する。",
    "前処理ロジックをドキュメント化し、サービング側の開発者が手動で同じロジックを再実装するように依頼する。"
  ],
  "correct": 0,
  "explanation": "トレーニング/サービング スキューを防ぐための最も効果的な方法は、同じ前処理ロジックを両方のフェーズで確実に共有することです。TensorFlow Transform (tf.Transform) を使用すると、Dataflow で実行されるトレーニング前のデータ処理ロジックを TensorFlow グラフとして保存できます。このグラフをモデルの一部として組み込むことで、サービング時にも全く同じ変換が自動的に適用されるようになります。他の選択肢（手動での再実装や独立したパイプラインの管理）は、人為的なミスやロジックの不一致を招きやすく、スキューの原因となります。"
}
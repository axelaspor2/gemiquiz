{
  "id": "pmle-20260217-",
  "exam_code": "PMLE",
  "domain": "ML パイプラインの自動化とオーケストレーション",
  "section": "エンドツーエンドの ML パイプライン開発",
  "topic": "トレーニングとサービング間の一貫したデータ前処理",
  "difficulty": "easy",
  "question": "Google Cloud の MLOps において、「トレーニング/サービング スキュー（training-serving skew）」の主な原因として最も適切なものはどれですか？",
  "options": [
    "トレーニング時とサービング時でデータの前処理ロジックや特徴量の定義が異なること",
    "モデルのトレーニングに使用するデータセットのサイズが不足していること",
    "予測リクエストのトラフィックが急激に増加し、レイテンシが発生すること",
    "モデルのトレーニングに使用したハイパーパラメータが最適でないこと"
  ],
  "correct": 0,
  "explanation": "トレーニング/サービング スキューは、トレーニング環境とサービング（予測）環境の間の不一致によって生じる、モデルのパフォーマンス低下の原因となる現象です。主な原因は、トレーニング時とサービング時でデータの前処理ステップや特徴量エンジニアリングのロジックが異なっていることです。これを防ぐために、TensorFlow Transform (tf.Transform) を使用して前処理ロジックをシリアライズしたり、Vertex AI Feature Store を使用して特徴量の定義を共通化したりすることが推奨されます。他の選択肢は、データの質やインフラの負荷、モデルのチューニングに関する問題であり、トレーニング/サービング スキューの直接的な定義ではありません。"
}
{
  "id": "pmle-20260127-",
  "exam_code": "PMLE",
  "domain": "AI ソリューションのモニタリング",
  "section": "AI ソリューションのモニタリング、テスト、トラブルシューティング",
  "topic": "特徴アトリビューションのドリフトモニタリング",
  "difficulty": "easy",
  "question": "Vertex AI エンドポイントにデプロイされたモデルで、特徴量ごとの入力データの分布の変化（Feature Drift）は正常にモニタリングできていますが、特徴アトリビューションのドリフト（Feature Attribution Drift）がレポートに表示されません。この原因として最も可能性が高いものはどれですか？",
  "options": [
    "モデルのデプロイ時に Vertex Explainable AI（説明可能性の設定）が構成されていない。",
    "モニタリングジョブで「トレーニング/サービング スキュー検出」が有効になっていない。",
    "特徴量のベースラインデータとして提供したトレーニングデータのスキーマが正しくない。",
    "エンドポイントに届く予測リクエストの数が、統計的な有意差を計算するのに十分でない。"
  ],
  "correct": 0,
  "explanation": "特徴アトリビューションのドリフトモニタリングは、Vertex Explainable AI を利用して各特徴量の予測に対する寄与度（アトリビューション）を計算し、その分布の変化を監視する機能です。そのため、モデルのデプロイ時に Explainable AI が正しく構成（Explanation specification の設定）されていないと、アトリビューションデータを生成できず、モニタリングレポートにも表示されません。一方で、特徴量自体の分布を監視する Feature Drift は、予測リクエストの入力値のみを使用するため、Explainable AI の設定がなくても動作します。したがって、アトリビューションのみが表示されない場合は、まず説明可能性の設定を確認するのが適切なトラブルシューティング手順です。"
}
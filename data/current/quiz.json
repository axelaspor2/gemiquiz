{
  "id": "pmle-20260127-",
  "exam_code": "PMLE",
  "domain": "AI ソリューションのモニタリング",
  "section": "AI ソリューションのモニタリング、テスト、トラブルシューティング",
  "topic": "継続的な評価指標の確立",
  "difficulty": "easy",
  "question": "機械学習モデルの運用（MLOps）における「継続的な評価（Continuous Evaluation）」の主な目的として、最も適切なものはどれですか？",
  "options": [
    "本番環境でのモデルのパフォーマンスを定期的に測定し、精度の低下（劣化）を検知する",
    "推論リクエストの応答時間を短縮するために、モデルのアーキテクチャを最適化する",
    "モデルのトレーニングに使用するデータのストレージコストを最小化する",
    "新しいモデルをデプロイする前に、テストデータセットで一度だけ評価を行う"
  ],
  "correct": 0,
  "explanation": "継続的な評価（Continuous Evaluation）は、本番環境にデプロイされたモデルが、時間の経過とともに変化する新しいデータに対しても期待通りのパフォーマンスを維持しているかを確認するためのプロセスです。これにより、モデルの劣化やデータドリフトを早期に発見し、再トレーニングの必要性を判断できます。他の選択肢について：Bはパフォーマンス最適化、Cはコスト管理、Dはデプロイ前の「静的な」評価の説明であり、運用中の「継続的な」評価の目的とは異なります。"
}
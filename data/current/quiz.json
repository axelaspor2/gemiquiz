{
  "id": "pmle-20260211-tpu-gpu",
  "exam_code": "PMLE",
  "domain": "プロトタイプの ML モデルへのスケーリング",
  "section": "トレーニングに適したハードウェアの選択",
  "topic": "TPU と GPU を使用した分散トレーニング",
  "difficulty": "easy",
  "question": "Cloud TPU を使用して分散トレーニングを行う際、ハードウェアの計算能力を最大限に活用し、メモリ効率を向上させるためのベストプラクティスはどれですか？",
  "options": [
    "bfloat16 を使用した混合精度トレーニングを有効にする",
    "計算の正確性を担保するために、すべての行列演算に float64（倍精度）を使用する",
    "ホスト CPU のリソースを節約するため、データのプリフェッチ（prefetch）を無効にする",
    "メモリ不足を回避するため、バッチサイズを可能な限り小さく（例：1）設定する"
  ],
  "correct": 0,
  "explanation": "Cloud TPU は bfloat16 形式の演算に最適化されており、混合精度トレーニングを使用することで、精度を維持しながらトレーニングを大幅に高速化し、メモリ消費を抑えることができます。これは Google Cloud が推奨する主要なパフォーマンス最適化手法です。一方、float64 は計算負荷が非常に高く TPU に適していません。また、TPU は計算速度が非常に速いため、プリフェッチを無効にしたりバッチサイズを小さくしすぎたりすると、データの供給が追いつかず TPU がアイドル状態になり、パフォーマンスが著しく低下します。"
}
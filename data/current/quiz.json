{
  "id": "pmle-20260223-google-ai",
  "exam_code": "PMLE",
  "domain": "AI ソリューションのモニタリング",
  "section": "AI ソリューションのリスク特定",
  "topic": "Google の責任ある AI への取り組み",
  "difficulty": "easy",
  "question": "Google の「責任ある AI への取り組み（AI Principles）」において、AI ソリューションのリスク特定に関連する原則である「不当なバイアスの発生や助長を避ける（Avoid creating or reinforcing unfair bias）」の説明として、最も適切なものはどれですか？",
  "options": [
    "人種、ジェンダー、性的指向などの機微な特徴に関連する不当な影響を回避するよう努め、状況に応じて適切なセーフガードを講じる。",
    "AI モデルの予測結果が常に 100% の精度であることを保証し、エラーが発生するリスクを完全に排除する。",
    "すべての AI 開発において、データのプライバシーよりもモデルの学習効率を優先し、可能な限り多くの個人データを収集する。",
    "AI モデルの意思決定プロセスを完全に秘密に保ち、第三者による評価や検証を受け付けない。"
  ],
  "correct": 0,
  "explanation": "正解は 0 です。Google の AI 原則の一つである「不当なバイアスの発生や助長を避ける」は、AI アルゴリズムやデータセットが不公平なバイアスを反映、助長、または創出することを防ぐことを目的としています。特に人種、ジェンダー、性的指向、信念などの機微な属性に基づく不当な影響を回避するために、適切な設計、テスト、およびモニタリングを通じてセーフガードを講じることを求めています。他の選択肢については、Bは技術的に不可能な目標であり、原則の主旨ではありません。Cは「プライバシー原則の組み込み」という別の原則に反します。Dは「人々に対する責任（説明責任）」や「科学的卓越性」といった透明性や検証可能性を重視する原則に反します。"
}
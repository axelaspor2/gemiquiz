{
  "id": "pmle-20260207-ai",
  "exam_code": "PMLE",
  "domain": "チーム内およびチーム間の連携によるデータとモデルの管理",
  "section": "ML テストのトラッキングと実行",
  "topic": "生成 AI ソリューションの評価",
  "difficulty": "hard",
  "question": "あなたは Vertex AI を使用して、既存の本番用 LLM と新しくファインチューニングした LLM の性能を比較しようとしています。評価対象は数千件のプロンプトに及び、推論能力や回答のトーンといった定性的な側面を含めた詳細な比較評価を、限られた人的リソースで迅速かつ大規模に行う必要があります。Google Cloud のベストプラクティスに基づき、最も推奨される評価手法はどれですか？",
  "options": [
    "Auto-SxS を使用し、autorater（評価用 LLM）によって 2 つのモデルの回答を直接比較（pairwise evaluation）させ、勝率と判断理由を取得する。",
    "Rapid Evaluation を使用し、ROUGE や BLEU などの計算ベースの指標を用いて、正解データ（Ground Truth）に対するトークンの重なりを定量的に比較する。",
    "Vertex AI Model Monitoring を構成し、本番環境での予測データとトレーニングデータの間の特徴量ドリフトを追跡して、モデルの劣化を検知する。",
    "各モデルに対して個別に Rapid Evaluation を実行し、静的ルーブリック（Static Rubric）を用いて 1-5 のスコアを算出した後、各モデルの平均スコアを比較する。"
  ],
  "correct": 0,
  "explanation": "モデル間の比較において、定性的な質（推論、トーン等）を大規模かつ迅速に評価するためのベストプラクティスは Auto-SxS (Automatic Side-by-Side) です。Auto-SxS は「autorater」と呼ばれる高性能な LLM が 2 つのモデルの出力を直接比較し、人間が行うのと同等の品質で詳細な理由付きの評価を提供します。計算ベースの指標 (ROUGE/BLEU) は生成 AI の質的な評価には不十分であり、個別スコアリング (pointwise) よりも直接比較 (pairwise) の方がモデル間の微妙な差異を検出するのに優れています。また、Model Monitoring は運用時の監視用であり、開発時のモデル比較には適しません。"
}
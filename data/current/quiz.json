{
  "id": "pmle-20260211-vertex-ai-reduction-",
  "exam_code": "PMLE",
  "domain": "プロトタイプの ML モデルへのスケーリング",
  "section": "トレーニングに適したハードウェアの選択",
  "topic": "Vertex AI 上の Reduction Server",
  "difficulty": "easy",
  "question": "Vertex AI で NVIDIA GPU を使用したマルチノード分散トレーニングを実行しています。ネットワーク帯域のボトルネックを解消し、オールリデュース（all-reduce）操作を高速化するために Reduction Server を導入しようとしていますが、期待通りに機能していません。構成を確認したところ、workerPoolSpecs[0] と workerPoolSpecs[1] には適切な GPU マシンとトレーニング用コンテナが設定されていました。Reduction Server を正しく有効にするために不足している設定はどれですか？",
  "options": [
    "workerPoolSpecs[2] を追加し、専用の Reduction Server コンテナイメージを指定したワーカーを配置する。",
    "すべてのワーカーノードで、環境変数として REDUCTION_SERVER_OPTIMIZE=TRUE を設定する。",
    "workerPoolSpecs[0] のマシンタイプを、GPU を搭載していない大容量メモリの n1-highmem-96 に変更する。",
    "トレーニングコード内で、分散戦略（Distribution Strategy）を ParameterServerStrategy に明示的に変更する。"
  ],
  "correct": 0,
  "explanation": "Vertex AI で Reduction Server を有効にするには、3番目のワーカープール（workerPoolSpecs[2]）を構成し、Google が提供する専用の Reduction Server コンテナイメージ（例: us-docker.pkg.dev/vertex-ai-restricted/training/reductionserver:latest）を指定する必要があります。このプール内のノードは「リデューサー」として機能し、GPU ノード間の勾配集約を最適化します。環境変数の設定だけでは有効になりません。また、Reduction Server はオールリデュース操作を最適化するものであり、ParameterServerStrategy（パラメータサーバー戦略）とは異なるアーキテクチャです。"
}
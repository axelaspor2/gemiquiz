{
  "quiz": {
    "id": "pmle-20260207-ml",
    "exam_code": "PMLE",
    "domain": "プロトタイプの ML モデルへのスケーリング",
    "section": "モデルの構築",
    "topic": "ML フレームワークとモデルアーキテクチャの選択",
    "difficulty": "hard",
    "question": "Vertex AI で Cloud TPU v3-8 を使用して TensorFlow モデルのトレーニングを行っていますが、スループットが期待よりも大幅に低くなっています。Cloud Monitoring でメトリクスを確認したところ、TensorCore のアイドル時間が長く、MXU（行列演算ユニット）の利用率が極めて低いことがわかりました。データパイプラインは tf.data を使用して Cloud Storage から TFRecord 形式でデータを読み込んでいます。この問題を解決するための最も適切なトラブルシューティング手順はどれですか？",
    "options": [
      "Vertex AI TensorBoard の Profiler を使用して実行プロファイルを分析し、tf.py_function のような Python オペレーションが入力パイプラインのボトルネックになっていないか確認した後、それらをネイティブの TensorFlow オペレーションに置き換える。",
      "データ転送のオーバーヘッドを削減するために、トレーニングデータのファイル形式を TFRecord から CSV に変更し、Cloud Storage の代わりに Filestore をマウントしてデータを読み込むようにパイプラインを再設計する。",
      "TPU コア間の重み同期の遅延を解消するために、Distribution Strategy を TPUStrategy から MultiWorkerMirroredStrategy に変更し、ネットワークトポロジを手動で最適化する。",
      "モデルの演算密度が低いために TPU が効率的に動作していない可能性があるため、バッチサイズを現在の値から大幅に縮小し、各コアへのデータ供給頻度を高めることでアイドル時間を相殺する。"
    ],
    "correct": 0,
    "explanation": "TPU のアイドル時間が長く MXU 利用率が低い状態は、多くの場合「入力パイプラインのボトルネック（Input-bound）」が発生していることを示しています。これは、TPU の計算速度に対してホスト CPU 側でのデータ供給（前処理や読み込み）が追いついていない状態です。`tf.py_function` は Python インタプリタで実行されるため、XLA コンパイルの対象外となり、ホスト CPU の負荷を高めてボトルネックの原因となります。Profiler を使用してこのような Python 演算を特定し、ネイティブな TensorFlow 演算に置き換えることが推奨される解決策です。他の選択肢について、(B) CSV は効率が悪く、(C) TPU では `TPUStrategy` を使用するのが正解であり、(D) バッチサイズを縮小することは通常 TPU の演算効率をさらに低下させるため不適切です。"
  },
  "message_id": "1469624264196882463",
  "channel_id": "1465902692101787799",
  "posted_at": "2026-02-07T09:22:08.982Z"
}
{
  "quiz": {
    "id": "pmle-20260211-cpu-gpu-tpu",
    "exam_code": "PMLE",
    "domain": "プロトタイプの ML モデルへのスケーリング",
    "section": "トレーニングに適したハードウェアの選択",
    "topic": "CPU・GPU・TPU・エッジデバイスの選択",
    "difficulty": "easy",
    "question": "Google Cloud でディープラーニングのワークロード（トレーニングおよび推論）を高速化するために、Google が独自に設計したカスタム ASIC（特定用途向け集積回路）はどれですか？",
    "options": [
      "Tensor Processing Unit (TPU)",
      "Graphics Processing Unit (GPU)",
      "Central Processing Unit (CPU)",
      "Field Programmable Gate Array (FPGA)"
    ],
    "correct": 0,
    "explanation": "正解は TPU（Tensor Processing Unit）です。TPU は、特に大規模なディープラーニング モデルのトレーニングや処理において高いパフォーマンスと電力効率を発揮するように Google が専用設計したアクセラレータです。GPU は汎用的な並列計算に適しており、CPU はデータの前処理や一般的な計算タスクに使用されます。FPGA は再構成可能な集積回路ですが、Google Cloud の ML ワークロード向け専用設計ハードウェアとしては TPU が該当します。"
  },
  "message_id": "1470951428712304825",
  "channel_id": "1465902692101787799",
  "posted_at": "2026-02-11T01:15:49.952Z"
}
{
  "quiz": {
    "id": "pmle-20260214-a-b",
    "exam_code": "PMLE",
    "domain": "モデルの提供とスケーリング",
    "section": "モデルの提供",
    "topic": "異なるモデルバージョンを使用した A/B テスト",
    "difficulty": "hard",
    "question": "あなたは、Vertex AI を使用して、現在の本番モデル（v1）と改善された新モデル（v2）の A/B テストを計画しています。システムのセキュリティ要件により、モデルは **プライベートエンドポイント** にデプロイする必要があります。トラフィックの 10% をモデル v2 に、残りの 90% をモデル v1 に動的に割り当てて比較評価を行いたい場合、Google Cloud が推奨するベストプラクティスはどれですか？",
    "options": [
      "モデル v1 とモデル v2 をそれぞれ個別のプライベートエンドポイントにデプロイし、クライアントアプリケーション側、またはカスタムプロキシ層でトラフィックの振り分けロジックを実装する。",
      "同一のプライベートエンドポイントに対して両方のモデルをデプロイし、gcloud ai endpoints deploy-model コマンドの --traffic-split フラグを使用して 90:10 の比率を指定する。",
      "両方のモデルを Model Registry に登録し、v1 に 'prod'、v2 に 'canary' というエイリアスを付与する。単一のプライベートエンドポイントに両方をデプロイし、エイリアス設定によって自動的にトラフィックが分割されるように構成する。",
      "プライベートエンドポイントの代わりに公開エンドポイントを使用し、VPC Service Controls を構成してネットワークアクセスを制限した上で、エンドポイントのネイティブなトラフィック分割機能を活用する。"
    ],
    "correct": 0,
    "explanation": "Vertex AI のプライベートエンドポイントは、現時点でネイティブのトラフィック分割機能をサポートしていません。この機能（--traffic-split フラグなど）は公開エンドポイントでのみ利用可能です。そのため、プライベートエンドポイント環境で A/B テストやカナリアリリースを実施する場合のベストプラクティスは、複数のエンドポイントに各モデルを個別にデプロイし、クライアントアプリケーションや API ゲートウェイ、またはプロキシ層などの上位レイヤーでトラフィックのルーティングを制御することです。選択肢 B は公開エンドポイントでのみ可能な操作であるため誤りです。選択肢 C のエイリアス機能はモデルのバージョン管理を容易にしますが、トラフィックを自動的に分割する機能は持っていません。選択肢 D は「プライベートエンドポイントを使用する」というセキュリティ要件を回避しているため、要件を満たす最適解ではありません。"
  },
  "message_id": "1472098044416884853",
  "channel_id": "1465902692101787799",
  "posted_at": "2026-02-14T05:12:04.154Z"
}
{
  "quiz": {
    "id": "pmle-20260203-pii-phi",
    "exam_code": "PMLE",
    "domain": "チーム内およびチーム間の連携によるデータとモデルの管理",
    "section": "組織全体のデータの探索と前処理",
    "topic": "PII・PHI などの機密データ処理とプライバシー",
    "difficulty": "easy",
    "question": "機械学習モデルのトレーニングに使用するデータセットに、氏名や電話番号などの個人識別情報（PII）が含まれていることが判明しました。Google Cloud のベストプラクティスに従い、データの有用性を維持しつつプライバシーリスクを最小限に抑えるための最も適切なアプローチはどれですか？",
    "options": [
      "Sensitive Data Protection（旧 Cloud DLP）を使用して、データを匿名化またはマスキングする。",
      "データセットを Cloud Storage に保存し、バケットレベルの IAM 権限のみでアクセスを制限する。",
      "データを暗号化し、トレーニングジョブを実行するサービスアカウントにのみ復号権限を与える。",
      "PII が含まれる列をプロジェクトの管理者のみが閲覧できるように BigQuery のデータセット権限を設定する。"
    ],
    "correct": 0,
    "explanation": "Google Cloud では、PII や PHI などの機密データを扱う際のベストプラクティスとして、Sensitive Data Protection を使用したデータの検出、分類、および匿名化（de-identification）を推奨しています。これにより、モデルのトレーニングに不要な機密情報を削除または変換しながら、データの統計的な有用性を維持することができます。他の選択肢はアクセス制御や暗号化に関するものですが、データそのものに含まれる機密情報を適切に処理してプライバシーを保護する根本的な解決策にはなりません。"
  },
  "message_id": "1468113052544270462",
  "channel_id": "1465902692101787799",
  "posted_at": "2026-02-03T05:17:08.130Z"
}
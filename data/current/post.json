{
  "quiz": {
    "id": "pmle-20260205-spark",
    "exam_code": "PMLE",
    "domain": "チーム内およびチーム間の連携によるデータとモデルの管理",
    "section": "Jupyter ノートブックを使用したモデルのプロトタイピング",
    "topic": "Spark カーネルの使用",
    "difficulty": "medium",
    "question": "データ サイエンティストが Vertex AI Workbench を使用して、Google Cloud Storage 上の数テラバイトのデータに対して PySpark を用いたデータ分析とモデルのプロトタイピングを行おうとしています。インフラストラクチャの管理（クラスターのサイジングやパッチ適用など）を回避しつつ、スケーラブルでインタラクティブな開発環境を最小限の構成で実現するためのベストプラクティスはどれですか？",
    "options": [
      "JupyterLab のランチャーから「Serverless for Apache Spark」セクションにある適切なランタイム テンプレートを選択し、サーバーレス Spark カーネルを使用する。",
      "標準の Python 3 カーネルを使用し、ノートブックのセル内で !pip install pyspark を実行して、Workbench インスタンスのローカル CPU リソースで分散処理を行う。",
      "既存の Dataproc クラスターの SSH トンネルを介して接続するために、Workbench のターミナルから手動で Spark マスタのアドレスを環境変数に設定する。",
      "プロトタイピングの各ステップを個別の Vertex AI Training ジョブとしてパッケージ化し、Jupyter ノートブックから API を介して逐次実行する。"
    ],
    "correct": 0,
    "explanation": "Google Cloud のベストプラクティスでは、運用オーバーヘッドを最小限に抑えつつ大規模な Spark 処理を行うために、Vertex AI Workbench での Serverless Spark インタラクティブ セッションの使用が推奨されています。これにより、Dataproc クラスターを明示的に作成・管理することなく、オンデマンドで Spark 計算リソースを利用できます。選択肢 B はローカルリソースに依存するため大規模データには不向きです。選択肢 C は手動のインフラ設定が必要であり、選択肢 D は対話的なプロトタイピングにおいて開発効率が低いため不適切です。"
  },
  "message_id": "1468838383219642460",
  "channel_id": "1465902692101787799",
  "posted_at": "2026-02-05T05:19:20.380Z"
}
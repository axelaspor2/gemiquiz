{
  "quiz": {
    "id": "pmle-20260209-gke-kubeflow",
    "exam_code": "PMLE",
    "domain": "プロトタイプの ML モデルへのスケーリング",
    "section": "モデルのトレーニング",
    "topic": "GKE 上の Kubeflow を使用したトレーニング",
    "difficulty": "easy",
    "question": "Google Kubernetes Engine (GKE) 上で Kubeflow を使用して TensorFlow モデルの分散トレーニングを実行する場合、Google Cloud が推奨するベストプラクティスはどれですか？",
    "options": [
      "TFJob カスタムリソースを使用して、トレーニングのライフサイクルと分散構成を管理する。",
      "標準的な Kubernetes の Deployment を使用して、手動で各 Pod に役割を割り当てる。",
      "Compute Engine インスタンスに SSH で接続し、各ノードでトレーニングスクリプトを直接実行する。",
      "App Engine を使用して、トレーニングジョブをスケーラブルなマネージドサービスとしてデプロイする。"
    ],
    "correct": 0,
    "explanation": "Kubeflow では、特定の ML フレームワーク（TensorFlow、PyTorch、XGBoost など）に最適化されたカスタムリソース（CRD）を提供しています。TensorFlow の場合、TFJob を使用することで、マスター、ワーカー、パラメータサーバーといった分散構成のセットアップや、トレーニング完了後のリソースの自動クリーンアップを簡単かつ確実に行うことができます。標準の Deployment は長時間実行されるサービス向けであり、バッチ処理であるトレーニングジョブには適していません。Compute Engine や App Engine の使用は、Kubeflow のオーケストレーション機能を活用できないため推奨されません。"
  },
  "message_id": "1470293106535698463",
  "channel_id": "1465902692101787799",
  "posted_at": "2026-02-09T05:39:53.465Z"
}
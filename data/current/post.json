{
  "quiz": {
    "id": "pde-20260125-",
    "exam_code": "PDE",
    "domain": "データの取り込みと処理",
    "section": "データ処理の実装",
    "topic": "エラーハンドリングと再試行戦略",
    "difficulty": "hard",
    "question": "あなたは、Cloud Pub/Sub からデータを受信し、Cloud Dataflow で変換処理を行って BigQuery に書き込むストリーミングパイプラインを管理しています。特定の形式不備を含むメッセージ（ポイズンピル）が原因で、Dataflow のワーカーが特定の要素の処理を繰り返し試行し、パイプライン全体にバックログが発生しています。システムの堅牢性を高め、処理の遅延を最小限に抑えるための Google Cloud のベストプラクティスはどれですか？",
    "options": [
      "Dataflow の処理ロジック内で try-catch ブロックを実装し、エラーが発生した要素をサイド出力（Side Output）として別の PCollection に分離し、デッドレターとして Cloud Storage または別の Pub/Sub トピックに書き出す。",
      "Dataflow ジョブの最大再試行回数を 0 に設定することで、エラーが発生した瞬間にジョブを失敗させ、不正なデータがパイプラインに留まるのを防ぐ。",
      "Pub/Sub の承認期限（Ack Deadline）を短く設定し、処理に失敗したメッセージがすぐに再配信されるようにすることで、ワーカーのアイドル時間を削減する。",
      "すべてのメッセージを BigQuery に直接書き込み、BigQuery のスキーマ検証機能を利用して不正なデータをフィルタリングする「スキーマオンリード」戦略を採用する。"
    ],
    "correct": 0,
    "explanation": "ストリーミングパイプラインにおける「ポイズンピル（一貫してエラーを引き起こすデータ）」への対処として、Google Cloud のベストプラクティスは「デッドレターキュー（DLQ）」パターンを採用することです。Dataflow では、サイド出力を使用して正常なデータと異常なデータを分離し、異常なデータを別のストレージに保存することで、パイプラインの停止を防ぎつつ、後から原因調査や再処理を可能にします。選択肢Bはパイプラインの可用性を損なうため不適切です。選択肢Cは再試行のループを加速させるだけで根本解決になりません。選択肢Dは、処理レイヤでのエラー（変換エラーなど）を解決するものではなく、書き込み時のエラーしか対処できません。"
  },
  "message_id": "1464846007203266715",
  "channel_id": "1298251380527726645",
  "posted_at": "2026-01-25T04:55:03.834Z"
}